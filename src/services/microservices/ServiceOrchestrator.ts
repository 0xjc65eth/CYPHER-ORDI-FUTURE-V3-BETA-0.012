/**
 * Microservices Orchestrator for CYPHER ORDi Future V3
 * Advanced service mesh architecture with auto-scaling and fault tolerance
 */

import { EventEmitter } from 'events';
import { EnhancedLogger } from '@/lib/enhanced-logger';
import { hmacSecurity } from '@/lib/security/HMACSecuritySystem';

// Service Architecture Types
export interface ServiceConfig {
  name: string;
  version: string;
  port: number;
  endpoints: ServiceEndpoint[];
  dependencies: string[];
  health: {
    endpoint: string;
    interval: number;
    timeout: number;
    retries: number;
  };
  scaling: {
    minInstances: number;
    maxInstances: number;
    targetCPU: number;
    targetMemory: number;
  };
  security: {
    requireAuth: boolean;
    permissions: string[];
    rateLimits: Record<string, number>;
  };
}

export interface ServiceEndpoint {
  path: string;
  method: 'GET' | 'POST' | 'PUT' | 'DELETE' | 'PATCH';
  handler: string;
  auth: boolean;
  rateLimit?: number;
  timeout?: number;
  cache?: {
    ttl: number;
    strategy: 'memory' | 'redis' | 'none';
  };
}

export interface ServiceInstance {
  id: string;
  config: ServiceConfig;
  status: 'starting' | 'healthy' | 'unhealthy' | 'stopped';
  lastHealth: number;
  metrics: ServiceMetrics;
  loadBalancer: LoadBalancer;
  circuitBreaker: CircuitBreaker;
}

export interface ServiceMetrics {
  requests: {
    total: number;
    success: number;
    errors: number;
    avgResponseTime: number;
  };
  resources: {
    cpu: number;
    memory: number;
    network: number;
  };
  health: {
    uptime: number;
    lastCheck: number;
    consecutiveFailures: number;
  };
}

export interface LoadBalancer {
  strategy: 'round_robin' | 'least_connections' | 'weighted' | 'ip_hash';
  instances: Array<{
    id: string;
    weight: number;
    connections: number;
    healthy: boolean;
  }>;
  currentIndex: number;
}

export interface CircuitBreaker {
  state: 'closed' | 'open' | 'half_open';
  failureCount: number;
  lastFailure: number;
  threshold: number;
  timeout: number;
  nextAttempt: number;
}

export interface ServiceRequest {
  id: string;
  service: string;
  endpoint: string;
  method: string;
  headers: Record<string, string>;
  body?: any;
  timeout: number;
  retries: number;
  metadata: {
    timestamp: number;
    correlationId: string;
    userId?: string;
    sessionId?: string;
  };
}

export interface ServiceResponse {
  requestId: string;
  status: number;
  data: any;
  headers: Record<string, string>;
  metadata: {
    processingTime: number;
    instanceId: string;
    cacheHit: boolean;
  };
}

export class ServiceOrchestrator extends EventEmitter {
  private logger: EnhancedLogger;
  private services: Map<string, ServiceInstance> = new Map();
  private serviceRegistry: Map<string, ServiceConfig[]> = new Map();
  private requestQueue: Map<string, ServiceRequest[]> = new Map();
  private cache: Map<string, { data: any; timestamp: number; ttl: number }> = new Map();
  private metrics: Map<string, ServiceMetrics> = new Map();
  private isRunning: boolean = false;

  // Predefined microservices
  private readonly CORE_SERVICES: ServiceConfig[] = [
    {
      name: 'arbitrage-service',
      version: '1.0.0',
      port: 3001,
      endpoints: [
        { path: '/opportunities', method: 'GET', handler: 'getOpportunities', auth: true },
        { path: '/execute', method: 'POST', handler: 'executeArbitrage', auth: true },
        { path: '/history', method: 'GET', handler: 'getHistory', auth: true, cache: { ttl: 300000, strategy: 'memory' } }
      ],
      dependencies: ['market-data-service', 'exchange-api-service'],
      health: { endpoint: '/health', interval: 30000, timeout: 5000, retries: 3 },
      scaling: { minInstances: 2, maxInstances: 10, targetCPU: 70, targetMemory: 80 },
      security: { requireAuth: true, permissions: ['arbitrage:read', 'arbitrage:execute'], rateLimits: { default: 100 } }
    },
    {
      name: 'ordinals-service',
      version: '1.0.0',
      port: 3002,
      endpoints: [
        { path: '/collections', method: 'GET', handler: 'getCollections', auth: false, cache: { ttl: 600000, strategy: 'memory' } },
        { path: '/inscriptions/:id', method: 'GET', handler: 'getInscription', auth: false },
        { path: '/analytics', method: 'GET', handler: 'getAnalytics', auth: true },
        { path: '/trade', method: 'POST', handler: 'executeTrade', auth: true }
      ],
      dependencies: ['market-data-service'],
      health: { endpoint: '/health', interval: 30000, timeout: 5000, retries: 3 },
      scaling: { minInstances: 3, maxInstances: 15, targetCPU: 70, targetMemory: 80 },
      security: { requireAuth: false, permissions: ['ordinals:read', 'ordinals:trade'], rateLimits: { default: 200 } }
    },
    {
      name: 'runes-service',
      version: '1.0.0',
      port: 3003,
      endpoints: [
        { path: '/pools', method: 'GET', handler: 'getPools', auth: false },
        { path: '/swap/quote', method: 'POST', handler: 'getSwapQuote', auth: true },
        { path: '/swap/execute', method: 'POST', handler: 'executeSwap', auth: true },
        { path: '/liquidity', method: 'POST', handler: 'manageLiquidity', auth: true }
      ],
      dependencies: ['market-data-service', 'blockchain-service'],
      health: { endpoint: '/health', interval: 30000, timeout: 5000, retries: 3 },
      scaling: { minInstances: 2, maxInstances: 12, targetCPU: 70, targetMemory: 80 },
      security: { requireAuth: true, permissions: ['runes:read', 'runes:trade'], rateLimits: { default: 150 } }
    },
    {
      name: 'portfolio-service',
      version: '1.0.0',
      port: 3004,
      endpoints: [
        { path: '/analytics/:address', method: 'GET', handler: 'getAnalytics', auth: true },
        { path: '/recommendations', method: 'GET', handler: 'getRecommendations', auth: true },
        { path: '/rebalance', method: 'POST', handler: 'rebalancePortfolio', auth: true },
        { path: '/tax-report', method: 'POST', handler: 'generateTaxReport', auth: true }
      ],
      dependencies: ['market-data-service', 'xverse-service'],
      health: { endpoint: '/health', interval: 30000, timeout: 5000, retries: 3 },
      scaling: { minInstances: 2, maxInstances: 8, targetCPU: 70, targetMemory: 80 },
      security: { requireAuth: true, permissions: ['portfolio:read', 'portfolio:manage'], rateLimits: { default: 50 } }
    },
    {
      name: 'trading-bot-service',
      version: '1.0.0',
      port: 3005,
      endpoints: [
        { path: '/start', method: 'POST', handler: 'startBot', auth: true },
        { path: '/stop', method: 'POST', handler: 'stopBot', auth: true },
        { path: '/status', method: 'GET', handler: 'getBotStatus', auth: true },
        { path: '/strategies', method: 'GET', handler: 'getStrategies', auth: true },
        { path: '/performance', method: 'GET', handler: 'getPerformance', auth: true }
      ],
      dependencies: ['market-data-service', 'hyperliquid-service'],
      health: { endpoint: '/health', interval: 30000, timeout: 5000, retries: 3 },
      scaling: { minInstances: 1, maxInstances: 5, targetCPU: 70, targetMemory: 80 },
      security: { requireAuth: true, permissions: ['trading:read', 'trading:execute'], rateLimits: { default: 30 } }
    },
    {
      name: 'ai-service',
      version: '1.0.0',
      port: 3006,
      endpoints: [
        { path: '/chat', method: 'POST', handler: 'processChat', auth: true },
        { path: '/voice', method: 'POST', handler: 'processVoice', auth: true },
        { path: '/analyze', method: 'POST', handler: 'analyzeData', auth: true },
        { path: '/recommendations', method: 'GET', handler: 'getRecommendations', auth: true }
      ],
      dependencies: ['market-data-service', 'knowledge-base-service'],
      health: { endpoint: '/health', interval: 30000, timeout: 5000, retries: 3 },
      scaling: { minInstances: 2, maxInstances: 10, targetCPU: 70, targetMemory: 80 },
      security: { requireAuth: true, permissions: ['ai:chat', 'ai:analyze'], rateLimits: { default: 100 } }
    },
    {
      name: 'market-data-service',
      version: '1.0.0',
      port: 3007,
      endpoints: [
        { path: '/prices', method: 'GET', handler: 'getPrices', auth: false, cache: { ttl: 30000, strategy: 'memory' } },
        { path: '/tickers', method: 'GET', handler: 'getTickers', auth: false, cache: { ttl: 60000, strategy: 'memory' } },
        { path: '/orderbook/:symbol', method: 'GET', handler: 'getOrderBook', auth: false },
        { path: '/history', method: 'GET', handler: 'getHistory', auth: false, cache: { ttl: 300000, strategy: 'memory' } }
      ],
      dependencies: [],
      health: { endpoint: '/health', interval: 30000, timeout: 5000, retries: 3 },
      scaling: { minInstances: 3, maxInstances: 20, targetCPU: 70, targetMemory: 80 },
      security: { requireAuth: false, permissions: [], rateLimits: { default: 500 } }
    },
    {
      name: 'notification-service',
      version: '1.0.0',
      port: 3008,
      endpoints: [
        { path: '/send', method: 'POST', handler: 'sendNotification', auth: true },
        { path: '/subscribe', method: 'POST', handler: 'subscribe', auth: true },
        { path: '/unsubscribe', method: 'DELETE', handler: 'unsubscribe', auth: true },
        { path: '/templates', method: 'GET', handler: 'getTemplates', auth: true }
      ],
      dependencies: [],
      health: { endpoint: '/health', interval: 30000, timeout: 5000, retries: 3 },
      scaling: { minInstances: 2, maxInstances: 8, targetCPU: 70, targetMemory: 80 },
      security: { requireAuth: true, permissions: ['notifications:send'], rateLimits: { default: 200 } }
    }
  ];

  constructor() {
    super();
    this.logger = new EnhancedLogger();
    
    this.logger.info('Service Orchestrator initialized', {
      component: 'ServiceOrchestrator',
      coreServices: this.CORE_SERVICES.length
    });
  }

  /**
   * Start the service orchestrator
   */
  async start(): Promise<void> {
    if (this.isRunning) {
      this.logger.warn('Service orchestrator already running');
      return;
    }

    try {
      this.isRunning = true;
      
      // Register core services
      await this.registerCoreServices();
      
      // Start health monitoring
      this.startHealthMonitoring();
      
      // Start metrics collection
      this.startMetricsCollection();
      
      // Start auto-scaling
      this.startAutoScaling();
      
      // Start circuit breaker monitoring
      this.startCircuitBreakerMonitoring();
      
      this.logger.info('Service orchestrator started');
      this.emit('started');

    } catch (error) {
      this.logger.error('Failed to start service orchestrator:', error);
      this.isRunning = false;
      throw error;
    }
  }

  /**
   * Stop the service orchestrator
   */
  async stop(): Promise<void> {
    if (!this.isRunning) return;

    try {
      this.isRunning = false;
      
      // Stop all services
      for (const [serviceName] of this.services) {
        await this.stopService(serviceName);
      }
      
      this.logger.info('Service orchestrator stopped');
      this.emit('stopped');

    } catch (error) {
      this.logger.error('Error stopping service orchestrator:', error);
    }
  }

  /**
   * Register a new service
   */
  async registerService(config: ServiceConfig): Promise<void> {
    try {
      const instance = await this.createServiceInstance(config);
      this.services.set(config.name, instance);
      
      // Add to registry
      if (!this.serviceRegistry.has(config.name)) {
        this.serviceRegistry.set(config.name, []);
      }
      this.serviceRegistry.get(config.name)!.push(config);
      
      this.logger.info('Service registered', {
        service: config.name,
        version: config.version,
        port: config.port
      });
      
      this.emit('serviceRegistered', { service: config.name, config });

    } catch (error) {
      this.logger.error('Failed to register service:', error);
      throw error;
    }
  }

  /**
   * Make request to a service
   */
  async callService(
    serviceName: string,
    endpoint: string,
    method: string = 'GET',
    data?: any,
    options?: {
      timeout?: number;
      retries?: number;
      headers?: Record<string, string>;
    }
  ): Promise<ServiceResponse> {
    const service = this.services.get(serviceName);
    if (!service) {
      throw new Error(`Service ${serviceName} not found`);
    }

    const request: ServiceRequest = {
      id: this.generateRequestId(),
      service: serviceName,
      endpoint,
      method,
      headers: options?.headers || {},
      body: data,
      timeout: options?.timeout || 30000,
      retries: options?.retries || 3,
      metadata: {
        timestamp: Date.now(),
        correlationId: this.generateCorrelationId()
      }
    };

    return this.executeServiceRequest(service, request);
  }

  /**
   * Get service health status
   */
  getServiceHealth(serviceName?: string): Record<string, any> {
    if (serviceName) {
      const service = this.services.get(serviceName);
      return service ? this.getInstanceHealth(service) : {};
    }

    const health: Record<string, any> = {};
    for (const [name, service] of this.services) {
      health[name] = this.getInstanceHealth(service);
    }
    return health;
  }

  /**
   * Get service metrics
   */
  getServiceMetrics(serviceName?: string): Record<string, ServiceMetrics> {
    if (serviceName) {
      const metrics = this.metrics.get(serviceName);
      return metrics ? { [serviceName]: metrics } : {};
    }

    return Object.fromEntries(this.metrics);
  }

  /**
   * Scale service instances
   */
  async scaleService(serviceName: string, instances: number): Promise<void> {
    const service = this.services.get(serviceName);
    if (!service) {
      throw new Error(`Service ${serviceName} not found`);
    }

    // Implement scaling logic
    const currentInstances = service.loadBalancer.instances.length;
    
    if (instances > currentInstances) {
      // Scale up
      for (let i = 0; i < instances - currentInstances; i++) {
        await this.addServiceInstance(service);
      }
    } else if (instances < currentInstances) {
      // Scale down
      for (let i = 0; i < currentInstances - instances; i++) {
        await this.removeServiceInstance(service);
      }
    }

    this.logger.info('Service scaled', {
      service: serviceName,
      from: currentInstances,
      to: instances
    });
  }

  /**
   * Private methods
   */

  private async registerCoreServices(): Promise<void> {
    for (const config of this.CORE_SERVICES) {
      await this.registerService(config);
    }
  }

  private async createServiceInstance(config: ServiceConfig): Promise<ServiceInstance> {
    const instance: ServiceInstance = {
      id: this.generateInstanceId(config.name),
      config,
      status: 'starting',
      lastHealth: Date.now(),
      metrics: {
        requests: { total: 0, success: 0, errors: 0, avgResponseTime: 0 },
        resources: { cpu: 0, memory: 0, network: 0 },
        health: { uptime: Date.now(), lastCheck: 0, consecutiveFailures: 0 }
      },
      loadBalancer: {
        strategy: 'round_robin',
        instances: [{
          id: this.generateInstanceId(config.name),
          weight: 1,
          connections: 0,
          healthy: true
        }],
        currentIndex: 0
      },
      circuitBreaker: {
        state: 'closed',
        failureCount: 0,
        lastFailure: 0,
        threshold: 5,
        timeout: 60000,
        nextAttempt: 0
      }
    };

    // Initialize metrics
    this.metrics.set(config.name, instance.metrics);

    return instance;
  }

  private async executeServiceRequest(
    service: ServiceInstance,
    request: ServiceRequest
  ): Promise<ServiceResponse> {
    const startTime = Date.now();
    
    try {
      // Check circuit breaker
      if (service.circuitBreaker.state === 'open') {
        if (Date.now() < service.circuitBreaker.nextAttempt) {
          throw new Error('Circuit breaker is open');
        }
        service.circuitBreaker.state = 'half_open';
      }

      // Get instance using load balancer
      const instance = this.selectInstance(service.loadBalancer);
      if (!instance || !instance.healthy) {
        throw new Error('No healthy instances available');
      }

      // Check cache
      const cacheKey = `${service.config.name}:${request.endpoint}:${JSON.stringify(request.body)}`;
      const cached = this.getFromCache(cacheKey);
      if (cached) {
        return {
          requestId: request.id,
          status: 200,
          data: cached,
          headers: {},
          metadata: {
            processingTime: Date.now() - startTime,
            instanceId: instance.id,
            cacheHit: true
          }
        };
      }

      // Execute request (mock implementation)
      const response = await this.mockServiceCall(service, request, instance);

      // Update circuit breaker on success
      if (service.circuitBreaker.state === 'half_open') {
        service.circuitBreaker.state = 'closed';
        service.circuitBreaker.failureCount = 0;
      }

      // Cache response if configured
      const endpoint = service.config.endpoints.find(ep => ep.path === request.endpoint);
      if (endpoint?.cache) {
        this.setCache(cacheKey, response.data, endpoint.cache.ttl);
      }

      // Update metrics
      this.updateMetrics(service.config.name, true, Date.now() - startTime);

      return response;

    } catch (error) {
      // Update circuit breaker on failure
      service.circuitBreaker.failureCount++;
      service.circuitBreaker.lastFailure = Date.now();
      
      if (service.circuitBreaker.failureCount >= service.circuitBreaker.threshold) {
        service.circuitBreaker.state = 'open';
        service.circuitBreaker.nextAttempt = Date.now() + service.circuitBreaker.timeout;
      }

      // Update metrics
      this.updateMetrics(service.config.name, false, Date.now() - startTime);

      throw error;
    }
  }

  private async mockServiceCall(
    service: ServiceInstance,
    request: ServiceRequest,
    instance: any
  ): Promise<ServiceResponse> {
    // Mock delay
    await new Promise(resolve => setTimeout(resolve, Math.random() * 100 + 50));

    // Mock response based on service type
    let mockData: any = { status: 'success', timestamp: Date.now() };

    switch (service.config.name) {
      case 'arbitrage-service':
        if (request.endpoint === '/opportunities') {
          mockData = {
            opportunities: [
              { pair: 'BTC/USD', buyExchange: 'Binance', sellExchange: 'Coinbase', profit: 0.5 },
              { pair: 'ETH/USD', buyExchange: 'Kraken', sellExchange: 'FTX', profit: 0.3 }
            ]
          };
        }
        break;
      
      case 'market-data-service':
        if (request.endpoint === '/prices') {
          mockData = {
            BTC: 45000,
            ETH: 3000,
            SOL: 100
          };
        }
        break;
      
      case 'portfolio-service':
        if (request.endpoint.includes('/analytics/')) {
          mockData = {
            totalValue: 100000,
            pnl: 5000,
            allocation: { BTC: 40, ETH: 30, Others: 30 }
          };
        }
        break;
    }

    return {
      requestId: request.id,
      status: 200,
      data: mockData,
      headers: { 'Content-Type': 'application/json' },
      metadata: {
        processingTime: Math.random() * 200 + 50,
        instanceId: instance.id,
        cacheHit: false
      }
    };
  }

  private selectInstance(loadBalancer: LoadBalancer): any {
    const healthyInstances = loadBalancer.instances.filter(i => i.healthy);
    if (healthyInstances.length === 0) return null;

    switch (loadBalancer.strategy) {
      case 'round_robin':
        const instance = healthyInstances[loadBalancer.currentIndex % healthyInstances.length];
        loadBalancer.currentIndex++;
        return instance;
      
      case 'least_connections':
        return healthyInstances.reduce((min, current) => 
          current.connections < min.connections ? current : min
        );
      
      default:
        return healthyInstances[0];
    }
  }

  private startHealthMonitoring(): void {
    setInterval(async () => {
      if (!this.isRunning) return;

      for (const [serviceName, service] of this.services) {
        try {
          // Mock health check
          const isHealthy = Math.random() > 0.05; // 95% success rate
          
          service.status = isHealthy ? 'healthy' : 'unhealthy';
          service.lastHealth = Date.now();
          
          if (!isHealthy) {
            service.metrics.health.consecutiveFailures++;
          } else {
            service.metrics.health.consecutiveFailures = 0;
          }

          // Update load balancer instance health
          service.loadBalancer.instances.forEach(instance => {
            instance.healthy = isHealthy;
          });

        } catch (error) {
          this.logger.error(`Health check failed for ${serviceName}:`, error);
          service.status = 'unhealthy';
        }
      }
    }, 30000); // Every 30 seconds
  }

  private startMetricsCollection(): void {
    setInterval(() => {
      if (!this.isRunning) return;

      for (const [serviceName, service] of this.services) {
        // Mock resource metrics
        service.metrics.resources = {
          cpu: Math.random() * 100,
          memory: Math.random() * 100,
          network: Math.random() * 1000
        };

        service.metrics.health.uptime = Date.now() - service.metrics.health.uptime;
        service.metrics.health.lastCheck = Date.now();
      }
    }, 10000); // Every 10 seconds
  }

  private startAutoScaling(): void {
    setInterval(() => {
      if (!this.isRunning) return;

      for (const [serviceName, service] of this.services) {
        const metrics = service.metrics;
        const scaling = service.config.scaling;
        const currentInstances = service.loadBalancer.instances.length;

        // Scale up if CPU or memory usage is high
        if ((metrics.resources.cpu > scaling.targetCPU || metrics.resources.memory > scaling.targetMemory) &&
            currentInstances < scaling.maxInstances) {
          this.scaleService(serviceName, currentInstances + 1);
        }
        
        // Scale down if resources are low and we have more than minimum instances
        else if (metrics.resources.cpu < scaling.targetCPU * 0.5 && 
                 metrics.resources.memory < scaling.targetMemory * 0.5 &&
                 currentInstances > scaling.minInstances) {
          this.scaleService(serviceName, currentInstances - 1);
        }
      }
    }, 60000); // Every minute
  }

  private startCircuitBreakerMonitoring(): void {
    setInterval(() => {
      if (!this.isRunning) return;

      for (const [serviceName, service] of this.services) {
        const cb = service.circuitBreaker;
        
        // Reset circuit breaker if timeout has passed
        if (cb.state === 'open' && Date.now() > cb.nextAttempt) {
          cb.state = 'half_open';
          this.logger.info('Circuit breaker reset to half-open', { service: serviceName });
        }
      }
    }, 30000); // Every 30 seconds
  }

  private async stopService(serviceName: string): Promise<void> {
    const service = this.services.get(serviceName);
    if (service) {
      service.status = 'stopped';
      this.services.delete(serviceName);
      this.metrics.delete(serviceName);
    }
  }

  private async addServiceInstance(service: ServiceInstance): Promise<void> {
    const newInstance = {
      id: this.generateInstanceId(service.config.name),
      weight: 1,
      connections: 0,
      healthy: true
    };
    
    service.loadBalancer.instances.push(newInstance);
  }

  private async removeServiceInstance(service: ServiceInstance): Promise<void> {
    if (service.loadBalancer.instances.length > service.config.scaling.minInstances) {
      service.loadBalancer.instances.pop();
    }
  }

  private updateMetrics(serviceName: string, success: boolean, responseTime: number): void {
    const metrics = this.metrics.get(serviceName);
    if (!metrics) return;

    metrics.requests.total++;
    if (success) {
      metrics.requests.success++;
    } else {
      metrics.requests.errors++;
    }

    // Update average response time
    metrics.requests.avgResponseTime = 
      (metrics.requests.avgResponseTime * (metrics.requests.total - 1) + responseTime) / metrics.requests.total;
  }

  private getInstanceHealth(service: ServiceInstance): any {
    return {
      status: service.status,
      uptime: Date.now() - service.metrics.health.uptime,
      lastCheck: service.lastHealth,
      instances: service.loadBalancer.instances.length,
      healthyInstances: service.loadBalancer.instances.filter(i => i.healthy).length,
      circuitBreakerState: service.circuitBreaker.state,
      metrics: service.metrics
    };
  }

  private generateInstanceId(serviceName: string): string {
    return `${serviceName}-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
  }

  private generateRequestId(): string {
    return `req-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
  }

  private generateCorrelationId(): string {
    return `corr-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
  }

  private getFromCache(key: string): any {
    const cached = this.cache.get(key);
    if (cached && Date.now() - cached.timestamp < cached.ttl) {
      return cached.data;
    }
    this.cache.delete(key);
    return null;
  }

  private setCache(key: string, data: any, ttl: number): void {
    this.cache.set(key, { data, timestamp: Date.now(), ttl });
  }
}

// Singleton instance
export const serviceOrchestrator = new ServiceOrchestrator();

// Service discovery and registry
export class ServiceRegistry {
  private static services: Map<string, ServiceConfig> = new Map();
  
  static register(config: ServiceConfig): void {
    this.services.set(config.name, config);
  }
  
  static discover(serviceName: string): ServiceConfig | null {
    return this.services.get(serviceName) || null;
  }
  
  static list(): ServiceConfig[] {
    return Array.from(this.services.values());
  }
}

// Export types and utilities
export { ServiceConfig, ServiceInstance, ServiceMetrics, LoadBalancer, CircuitBreaker };